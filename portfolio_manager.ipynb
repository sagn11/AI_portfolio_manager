{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c95e56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0232c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c3505fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model \n",
    "model=Ollama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e55c62",
   "metadata": {},
   "source": [
    "Part 1- Portfolio Developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48623377",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Input Prompt template\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are an intelligent investment assistant.\n",
    "\n",
    "Your job is to extract structured data from the user's natural language prompt.\n",
    "\n",
    "**You must return a valid Python dictionary string, and nothing else.**\n",
    "\n",
    "The dictionary should contain the following keys:\n",
    "\n",
    "- \"sector\"\n",
    "- \"investment_type\"\n",
    "- \"investment_goal\"\n",
    "- \"risk_appetite\"\n",
    "- \"investment_horizon\" (as an integer number of years)\n",
    "- \"principal_amount\" (in numeric format, no currency symbols)\n",
    "- \"final_amount\" (in numeric format)\n",
    "- \"number_of_years\"\n",
    "- \"growth_rate\" (as a percentage, no % sign — leave blank if not specified)\n",
    "\n",
    "**Constraints:**\n",
    "- Only use these sectors: [\"IT\", \"Banking & Finance\", \"Pharma\", \"Energy\", \"FMCG\"]\n",
    "- If a field is missing in the prompt, set its value to an empty string or `None` (but keep the key).\n",
    "- You must return only the dictionary (as a single-line valid Python dictionary string). Ensure all keys are present, braces are properly closed, and the syntax is correct.\n",
    "\n",
    "Example:\n",
    "{{\n",
    "    \"sector\": \"Pharma\",\n",
    "    \"investment_type\": \"lumpsum\",\n",
    "    \"investment_goal\": \"wealth creation\",\n",
    "    \"risk_appetite\": \"medium\",\n",
    "    \"investment_horizon\": 5,\n",
    "    \"principal_amount\": 100000,\n",
    "    \"final_amount\": 200000,\n",
    "    \"number_of_years\": 5,\n",
    "    \"growth_rate\": \"\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b43cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ticker names\n",
    "sector_tickers = {\n",
    "    \"IT\": [\n",
    "        \"TCS\", \"INFY\", \"WIPRO\", \"HCLTECH\", \"TECHM\", \"LTIM\", \"PERSISTENT\", \"COFORGE\", \n",
    "        \"MPHASIS\", \"BSOFT\", \"SONATSOFTW\", \"CYIENT\", \"ZENSARTECH\", \"NIITLTD\", \n",
    "        \"KELLTONTEC\", \"TATAELXSI\", \"ECLERX\", \"NEWGEN\", \"INTELLECT\", \"HAPPSTMNDS\"\n",
    "    ],\n",
    "    \"Banking & Finance\": [\n",
    "        \"HDFCBANK\", \"ICICIBANK\", \"SBIN\", \"KOTAKBANK\", \"AXISBANK\", \"INDUSINDBK\", \"YESBANK\", \n",
    "        \"FEDERALBNK\", \"IDFCFIRSTB\", \"BANDHANBNK\", \"RBLBANK\", \"PNB\", \"CANBK\", \"BANKBARODA\", \n",
    "        \"UNIONBANK\", \"AUBANK\", \"IDBI\", \"UJJIVANSFB\", \"CENTRALBK\", \"SOUTHBANK\"\n",
    "    ],\n",
    "    \"Pharma\": [\n",
    "        \"SUNPHARMA\", \"DIVISLAB\", \"DRREDDY\", \"CIPLA\", \"LUPIN\", \"BIOCON\", \"TORNTPHARM\", \n",
    "        \"AUROPHARMA\", \"ZYDUSLIFE\", \"ALKEM\", \"GLAND\", \"IPCALAB\", \"PFIZER\", \n",
    "        \"ABBOTINDIA\", \"SANOFI\", \"NATCOPHARM\", \"GRANULES\", \"AJANTPHARM\", \n",
    "        \"JUBLPHARMA\", \"INDOCO\"\n",
    "    ],\n",
    "    \"Energy\": [\n",
    "        \"RELIANCE\", \"ONGC\", \"NTPC\", \"POWERGRID\", \"TATAPOWER\", \"ADANIGREEN\", \n",
    "        \"ADANITRANS\", \"NHPC\", \"GAIL\", \"OIL\", \"IOC\", \"BPCL\", \"HPCL\", \n",
    "        \"JSWENERGY\", \"SJVN\", \"TORNTPOWER\", \"CESC\", \"NLCINDIA\", \"BHEL\", \"COALINDIA\"\n",
    "    ],\n",
    "    \"FMCG\": [\n",
    "        \"HINDUNILVR\", \"ITC\", \"NESTLEIND\", \"BRITANNIA\", \"DABUR\", \"MARICO\", \n",
    "        \"GODREJCP\", \"COLPAL\", \"EMAMILTD\", \"VBL\", \"TATACONSUM\", \"UBL\", \n",
    "        \"RADICO\", \"ZYDUSWELL\", \"HATSUN\", \"KRBL\", \"MANAPPURAM\", \n",
    "        \"HERITGFOOD\", \"EVEREADY\", \"JYOTHYLAB\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf8339eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty_50_comp=[\n",
    "    \"HDFCBANK\",\n",
    "    \"ICICIBANK\",\n",
    "    \"RELIANCE\",\n",
    "    \"INFY\",\n",
    "    \"BHARTIARTL\",\n",
    "    \"ITC\",\n",
    "    \"LT\",\n",
    "    \"TCS\",\n",
    "    \"AXISBANK\",\n",
    "    \"KOTAKBANK\",\n",
    "    \"SBIN\",\n",
    "    \"M&M\",\n",
    "    \"BAJFINANCE\",\n",
    "    \"HINDUNILVR\",\n",
    "    \"SUNPHARMA\",\n",
    "    \"ULTRACEMCO\",\n",
    "    \"WIPRO\",\n",
    "    \"NTPC\",\n",
    "    \"ASIANPAINT\",\n",
    "    \"HCLTECH\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "349d9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def beta_risk_level(risk):\n",
    "    if risk==\"low\":\n",
    "        return (0.0,0.8)\n",
    "    if risk==\"moderate\":\n",
    "        return (0.8,1.2)\n",
    "    if risk==\"high\":\n",
    "        return (1.2,2.5)\n",
    "    if risk==\"\":\n",
    "        return(0.8,1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad4e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weights(dict):\n",
    "    total_cagr = sum(data[\"5yr_CAGR\"] for data in dict.values())\n",
    "    weights_calculated = {\n",
    "    ticker: data[\"5yr_CAGR\"] / total_cagr\n",
    "    for ticker, data in dict.items()\n",
    "    }\n",
    "    return weights_calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a2f11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_human_template = \"\"\"\n",
    "Original Input:\n",
    "{input}\n",
    "\n",
    "Selected Stocks:\n",
    "{results}\n",
    "\n",
    "Portfolio Weights:\n",
    "{weights}\n",
    "\"\"\"\n",
    "explanation_system_template = \"\"\"\n",
    "You are a financial advisor assistant that explains an investment portfolio to the user in clear, professional, and engaging language.\n",
    "\n",
    "You will be given:\n",
    "- The user's original investment intent (as natural language)\n",
    "- A dictionary of selected stocks with their financial metrics\n",
    "- A dictionary of weights (allocation percentages)\n",
    "\n",
    "Your job is to:\n",
    "1. Summarize the user's investment preferences (sector, risk, growth, time).\n",
    "2. List each selected stock along with its rationale for selection:\n",
    "    - 5yr CAGR\n",
    "    - ROE, ROCE\n",
    "    - PE ratio\n",
    "    - Beta (estimated)\n",
    "    - Debt-to-equity\n",
    "3. Explain why each stock fits the user's risk and return profile.\n",
    "4. Clearly state the portfolio weights and how much of the principal should be invested in each.\n",
    "5. End with a short paragraph about the portfolio's strengths and its alignment with the user's goals.\n",
    "\n",
    "Be crisp, confident, and use easy-to-understand finance language. Keep it factual and structured, but not robotic.\n",
    "\n",
    "Do NOT add disclaimers or legal text unless asked.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a8d0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_beta(pe=None, roce=None, roe=None, debt_to_equity=None, market_cap=None):\n",
    "    # Normalize inputs to risk scale (0 to 1), based on common Indian market ranges\n",
    "    risk = 0\n",
    "\n",
    "    if pe is not None:\n",
    "        risk += min(pe / 40, 1) * 0.25  # High P/E → growth → higher risk\n",
    "    if roce is not None:\n",
    "        risk += max(0, (20 - roce) / 20) * 0.25  # Lower ROCE → higher risk\n",
    "    if roe is not None:\n",
    "        risk += max(0, (20 - roe) / 20) * 0.15  # Lower ROE → more risk\n",
    "    if debt_to_equity is not None:\n",
    "        risk += min(debt_to_equity / 2, 1) * 0.25  # Higher leverage → more risk\n",
    "    if market_cap is not None:\n",
    "        if market_cap < 5000:       # Small cap\n",
    "            risk += 0.1\n",
    "        elif market_cap < 20000:    # Mid cap\n",
    "            risk += 0.05\n",
    "\n",
    "    # Map risk to beta range (0.6 to 2.0)\n",
    "    beta = 0.6 + (1.4 * min(risk, 1.0))\n",
    "    return round(beta, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c009aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def save_portfolio_with_pandas(results, weights, filename=\"portfolio.csv\"):\n",
    "    data = []\n",
    "    for ticker, metrics in results.items():\n",
    "        entry = metrics.copy()  # Don't mutate original data\n",
    "        entry['ticker'] = ticker\n",
    "        entry['weight'] = round(weights.get(ticker, 0), 4)  # Safe access + rounding\n",
    "        data.append(entry)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)  # <- Save the CSV file\n",
    "    print(f\"✅ Portfolio saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3950b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re\n",
    "\n",
    "def get_finology_ratios(ticker):\n",
    "    url = f\"https://ticker.finology.in/company/{ticker}\"\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Comment this line to see browser\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Wait for a known element to make sure the page is fully loaded\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, \"//div[contains(@class,'compess')][small[contains(text(),'P/E')]]\")))\n",
    "\n",
    "        # Get the current CAGR text to compare after click\n",
    "        old_cagr_text = driver.find_element(By.ID, \"pricereturn\").text.strip()\n",
    "\n",
    "        # Click the 5Yr CAGR button\n",
    "        cagr_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[data-duration='5Yr']\")))\n",
    "        cagr_button.click()\n",
    "\n",
    "        # Wait for CAGR value to change\n",
    "        wait.until(lambda d: d.find_element(By.ID, \"pricereturn\").text.strip() != old_cagr_text)\n",
    "\n",
    "        # Now fetch updated CAGR value\n",
    "        cagr_text = driver.find_element(By.ID, \"pricereturn\").text.strip()\n",
    "\n",
    "        # Helper functions\n",
    "        def get_text(xpath):\n",
    "            try:\n",
    "                return driver.find_element(By.XPATH, xpath).text.strip()\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        def parse_number(text):\n",
    "            if not text:\n",
    "                return None\n",
    "            text = text.replace(',', '').replace('%', '').strip()\n",
    "            try:\n",
    "                return float(text)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        ratios = {}\n",
    "        ratios['PE'] = parse_number(get_text(\"//div[contains(@class,'compess')][small[contains(text(),'P/E')]]/p\"))\n",
    "        ratios['ROCE'] = parse_number(get_text(\"//div[contains(@class,'compess')][small[contains(text(),'ROCE')]]//span[@class='Number']\"))\n",
    "        ratios['ROE'] = parse_number(get_text(\"//div[contains(@class,'compess')][small[contains(text(),'ROE')]]//span[@class='Number']\"))\n",
    "        ratios['Debt_Equity'] = parse_number(get_text(\"//div[@id='mainContent_divDebtEquity']//span[@class='Number']\"))\n",
    "        ratios['Market_Cap_Cr'] = parse_number(get_text(\"//p/span[@class='Number']\"))\n",
    "\n",
    "        match = re.search(r\"([\\d.]+)\", cagr_text)\n",
    "        ratios['5yr_CAGR'] = float(match.group(1)) if match else None\n",
    "\n",
    "        return ratios\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error scraping {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a62889b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PE': 22.91, 'ROCE': 15.26, 'ROE': 16.97, 'Debt_Equity': None, 'Market_Cap_Cr': 2016.0, '5yr_CAGR': 12.5}\n"
     ]
    }
   ],
   "source": [
    "print(get_finology_ratios(\"HDFCBANK\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "675c2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def is_nifty_moving(threshold=1.2):\n",
    "    \"\"\"\n",
    "    Checks if Nifty 50 has moved more than the given threshold (%) in the last trading day.\n",
    "\n",
    "    Args:\n",
    "        threshold (float): Percentage move to consider significant (default: 1.2%)\n",
    "\n",
    "    Returns:\n",
    "        bool: True if Nifty moved more than threshold, else False\n",
    "    \"\"\"\n",
    "    nifty = yf.Ticker(\"^NSEI\")  # Nifty 50 index\n",
    "    hist = nifty.history(period=\"2d\")\n",
    "\n",
    "    if len(hist) < 2:\n",
    "        print(\"⚠️ Not enough historical data.\")\n",
    "        return False\n",
    "\n",
    "    latest = hist['Close'].iloc[-1]\n",
    "    prev = hist['Close'].iloc[-2]\n",
    "    change_pct = abs((latest - prev) / prev) * 100\n",
    "\n",
    "    print(f\"📊 Nifty moved {change_pct:.2f}% in the last 24h.\")\n",
    "    return change_pct >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91d34021",
   "metadata": {},
   "outputs": [],
   "source": [
    "##result_dict contains the principal, years in a structured format\n",
    "# Human/user prompt — this is where {input} goes\n",
    "def portfolio_developer(input):\n",
    "    # Check Nifty movement\n",
    "    if not is_nifty_moving():\n",
    "        print(\"✅ Nifty is stable. Using cached beta data with smart filtering.\")\n",
    "\n",
    "        # Parse user inputs first\n",
    "        human_template = \"{input}\"\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(system_template),\n",
    "            HumanMessagePromptTemplate.from_template(human_template),\n",
    "        ])\n",
    "        chain = prompt | model | StrOutputParser()\n",
    "        result_dict_string = chain.invoke({\"input\": input})\n",
    "        print(result_dict_string)\n",
    "\n",
    "        import ast\n",
    "        result_dict = ast.literal_eval(result_dict_string)\n",
    "\n",
    "        principal = int(result_dict[\"principal_amount\"])\n",
    "        years = int(result_dict[\"investment_horizon\"])\n",
    "        risk = result_dict[\"risk_appetite\"]\n",
    "\n",
    "        if result_dict[\"growth_rate\"] == \"\":\n",
    "            final_amount = int(result_dict[\"final_amount\"])\n",
    "            growth_rate = (final_amount / principal) ** (1 / years) - 1\n",
    "        else:\n",
    "            growth_rate = float(result_dict[\"growth_rate\"])\n",
    "\n",
    "        beta_low, beta_high = beta_risk_level(risk)\n",
    "\n",
    "        # Load and filter cached CSV\n",
    "        df = pd.read_csv(\"merged_beta_cache.csv\")\n",
    "\n",
    "        def is_valid_row(row):\n",
    "            try:\n",
    "                beta = float(row[\"Estimated_Beta\"])\n",
    "                cagr = float(row[\"5yr_CAGR\"])\n",
    "                return (beta <= beta_high + 0.2) and (growth_rate - 6 <= cagr <= growth_rate + 6)\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        filtered_df = df[df.apply(is_valid_row, axis=1)].head(4)\n",
    "\n",
    "        if filtered_df.empty:\n",
    "            print(\"⚠️ No stocks matched the user criteria in cache.\")\n",
    "            return \"No valid portfolio could be created from cached data.\"\n",
    "\n",
    "        results = {\n",
    "            row[\"Ticker\"]: {\n",
    "                \"PE\": row[\"PE\"],\n",
    "                \"ROCE\": row[\"ROCE\"],\n",
    "                \"ROE\": row[\"ROE\"],\n",
    "                \"Debt_Equity\": row[\"Debt_Equity\"],\n",
    "                \"Market_Cap_Cr\": row[\"Market_Cap_Cr\"],\n",
    "                \"5yr_CAGR\": row[\"5yr_CAGR\"]\n",
    "            }\n",
    "            for _, row in filtered_df.iterrows()\n",
    "        }\n",
    "\n",
    "        weights = calc_weights(results)\n",
    "\n",
    "        prompt2 = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(explanation_system_template),\n",
    "            HumanMessagePromptTemplate.from_template(explanation_human_template),\n",
    "        ])\n",
    "        chain2 = prompt2 | model | StrOutputParser()\n",
    "\n",
    "        output = chain2.invoke({\n",
    "            \"input\": input,\n",
    "            \"results\": results,\n",
    "            \"weights\": weights\n",
    "        })\n",
    "\n",
    "        save_portfolio_with_pandas(results, weights, filename=\"portfolio.csv\")\n",
    "        return output\n",
    "\n",
    "    # 🚨 If Nifty has moved → run original full scraping pipeline (unchanged)\n",
    "    print(\"🚨 Nifty movement detected. Running full scraping pipeline...\")\n",
    "    human_template =\"{input}\"\n",
    "\n",
    "    # Build the full ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        HumanMessagePromptTemplate.from_template(human_template),\n",
    "    ])\n",
    "    chain=prompt| model | StrOutputParser()\n",
    "    result_dict_string = chain.invoke({\"input\": input})\n",
    "    import ast\n",
    "    print(result_dict_string)  # inspect this\n",
    "\n",
    "    result_dict = ast.literal_eval(result_dict_string)\n",
    "\n",
    "\n",
    "    principal=int(result_dict[\"principal_amount\"])\n",
    "    years=int(result_dict[\"investment_horizon\"])\n",
    "    risk=result_dict[\"risk_appetite\"]\n",
    "    sector=result_dict[\"sector\"]\n",
    "    if result_dict[\"growth_rate\"]==\"\":\n",
    "        final_amount=int(result_dict[\"final_amount\"])\n",
    "        growth_rate = (final_amount / principal) ** (1 / years) - 1\n",
    "    else:\n",
    "        growth_rate=float(result_dict[\"growth_rate\"])\n",
    "    if growth_rate < 10:\n",
    "        print(\"⚠️ Warning: Growth rate too low for equity investing. Consider debt instruments instead.\")\n",
    "    \n",
    "        print(\"Low growth rate detected. This may take longer as fewer companies match the criteria.\")\n",
    "\n",
    "    beta_low,beta_high=beta_risk_level(risk)\n",
    "    if sector==\"\":\n",
    "        companies=nifty_50_comp\n",
    "    else:\n",
    "        companies=sector_tickers[sector]\n",
    "    results = {}\n",
    "    c=0\n",
    "    i=0\n",
    "\n",
    "\n",
    "    while c < 4 and i < len(companies):\n",
    "        slug = companies[i]\n",
    "        data = get_finology_ratios(slug)\n",
    "        try:\n",
    "            PE = float(data[\"PE\"])\n",
    "            ROCE = float(data[\"ROCE\"])\n",
    "            ROE = float(data[\"ROE\"])\n",
    "            Market_cap = float(data[\"Market_Cap_Cr\"])\n",
    "            debt_equity = float(data[\"Debt_Equity\"])\n",
    "            cagr = float(data.get(\"5yr_CAGR\", 0))\n",
    "        except (ValueError, TypeError):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        beta_data = estimate_beta(pe=PE, roce=ROCE, roe=ROE, debt_to_equity=debt_equity, market_cap=Market_cap)\n",
    "        print(f\"\\nCompany: {slug}\")\n",
    "        print(f\"  Estimated Beta: {beta_data:.2f} | Max Acceptable beta :  {beta_high})\")\n",
    "        print(f\"  Company 5yr CAGR: {data['5yr_CAGR']} | Target Growth Rate: {growth_rate:.2f} ± 6\")\n",
    "        if ( beta_data <= beta_high + 0.2) and (growth_rate - 6<= cagr <= growth_rate + 6):\n",
    "            print(data)\n",
    "            results[slug] = data\n",
    "            c += 1\n",
    "    \n",
    "        i += 1\n",
    "        time.sleep(random.uniform(2.5, 5.0))  # Respect Screener's server\n",
    "    portfolio_weights=calc_weights(results)\n",
    "\n",
    "    prompt2 = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(explanation_system_template),\n",
    "        HumanMessagePromptTemplate.from_template(explanation_human_template),\n",
    "    ])\n",
    "    chain2=prompt2|model|StrOutputParser()\n",
    "    output = chain2.invoke({\n",
    "        \"input\": input,\n",
    "        \"results\": results,\n",
    "        \"weights\": portfolio_weights\n",
    "    })\n",
    "    print(output)\n",
    "    save_portfolio_with_pandas(results, portfolio_weights, filename=\"portfolio.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7686e9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Nifty moved 0.19% in the last 24h.\n",
      "✅ Nifty is stable. Using cached beta data with smart filtering.\n",
      "{\"sector\": \"IT\", \"investment_type\": \" lumpsum\", \"investment_goal\": \"aggressive growth\", \"risk_appetite\": \"high\", \"growth_rate\": \"18\", \"investment_horizon\": 5, \"principal_amount\": 100000, \"final_amount\": None, \"number_of_years\": 5}\n",
      "⚠️ No stocks matched the user criteria in cache.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No valid portfolio could be created from cached data.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=\"I'm investing ₹1,00,000 in the IT sector over 5 years. My goal is aggressive growth — I'm okay with high risk and want an annual return of around 18%. Suggest the best stocks for this.\"\n",
    "portfolio_developer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cafc51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed MARUTI\n",
      "[!] Error scraping M&M: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x9a3b03+62899]\n",
      "\tGetHandleVerifier [0x0x9a3b44+62964]\n",
      "\t(No symbol) [0x0x7d10f3]\n",
      "\t(No symbol) [0x0x81980e]\n",
      "\t(No symbol) [0x0x819bab]\n",
      "\t(No symbol) [0x0x8625c2]\n",
      "\t(No symbol) [0x0x83e554]\n",
      "\t(No symbol) [0x0x85fd81]\n",
      "\t(No symbol) [0x0x83e306]\n",
      "\t(No symbol) [0x0x80d670]\n",
      "\t(No symbol) [0x0x80e4e4]\n",
      "\tGetHandleVerifier [0x0xc04793+2556483]\n",
      "\tGetHandleVerifier [0x0xbffd02+2537394]\n",
      "\tGetHandleVerifier [0x0x9ca2fa+220586]\n",
      "\tGetHandleVerifier [0x0x9baae8+157080]\n",
      "\tGetHandleVerifier [0x0x9c141d+184013]\n",
      "\tGetHandleVerifier [0x0x9aba68+95512]\n",
      "\tGetHandleVerifier [0x0x9abc10+95936]\n",
      "\tGetHandleVerifier [0x0x996b5a+9738]\n",
      "\tBaseThreadInitThunk [0x0x76a95d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x7712d09b+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x7712d021+561]\n",
      "\n",
      "⚠️ Skipped M&M: Missing ratio data\n",
      "✅ Processed HDFCLIFE\n",
      "✅ Processed ICICIPRULI\n",
      "✅ Processed LTI\n",
      "✅ Processed COFORGE\n",
      "✅ Processed DABUR\n",
      "✅ Processed PIDILITIND\n",
      "✅ Processed EICHERMOT\n",
      "✅ Processed TATAMOTORS\n",
      "✅ Processed POWERGRID\n",
      "✅ Processed HAVELLS\n",
      "✅ Processed GODREJCP\n",
      "✅ Processed DIVISLAB\n",
      "✅ Processed DRREDDY\n",
      "✅ Processed LICHSGFIN\n",
      "✅ Processed JSWSTEEL\n",
      "✅ Processed ADANIPORTS\n",
      "✅ Processed BHARTIARTL\n",
      "✅ Processed TATACHEM\n",
      "✅ Processed ABB\n",
      "\n",
      "📁 Done. Saved 20 entries to beta_cache_data2.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "# Your cache universe\n",
    "beta_cache = [\n",
    "    \"HDFCBANK\", \"ICICIBANK\", \"SBIN\", \"KOTAKBANK\", \"AXISBANK\",\n",
    "    \"INFY\", \"TCS\", \"HCLTECH\", \"WIPRO\",\n",
    "    \"SUNPHARMA\",\n",
    "    \"RELIANCE\", \"NTPC\",\n",
    "    \"HINDUNILVR\", \"ITC\", \"NESTLEIND\",\n",
    "    \"ASIANPAINT\", \"ULTRACEMCO\",\n",
    "    \"BAJFINANCE\", \"LT\"\n",
    "]\n",
    "tier2_reactive = [  # Conditional scrape\n",
    "    \"MARUTI\", \"M&M\", \"HDFCLIFE\", \"ICICIPRULI\", \"LTI\", \"COFORGE\", \"DABUR\",\n",
    "    \"PIDILITIND\", \"EICHERMOT\", \"TATAMOTORS\", \"POWERGRID\", \"HAVELLS\", \"GODREJCP\",\n",
    "    \"DIVISLAB\", \"DRREDDY\", \"LICHSGFIN\", \"JSWSTEEL\", \"ADANIPORTS\", \"BHARTIARTL\",\n",
    "    \"TATACHEM\", \"ABB\"\n",
    "]\n",
    "# Assuming these exist\n",
    "\n",
    "\n",
    "\n",
    "# Output list\n",
    "data = []\n",
    "\n",
    "for ticker in tier2_reactive:\n",
    "    try:\n",
    "        ratios = get_finology_ratios(ticker)\n",
    "\n",
    "        if not ratios:\n",
    "            print(f\"⚠️ Skipped {ticker}: Missing ratio data\")\n",
    "            continue\n",
    "\n",
    "        beta = estimate_beta(\n",
    "            pe=ratios.get(\"PE\"),\n",
    "            roce=ratios.get(\"ROCE\"),\n",
    "            roe=ratios.get(\"ROE\"),\n",
    "            debt_to_equity=ratios.get(\"Debt_Equity\"),\n",
    "            market_cap=ratios.get(\"Market_Cap_Cr\")\n",
    "        )\n",
    "\n",
    "        entry = {\n",
    "            \"Ticker\": ticker,\n",
    "            \"CAGR\": ratios.get(\"5yr_CAGR\"),\n",
    "            \"Estimated_Beta\": beta\n",
    "        }\n",
    "\n",
    "        data.append(entry)\n",
    "        print(f\"✅ Processed {ticker}\")\n",
    "\n",
    "        time.sleep(1)  # Optional: Be polite if scraping\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error with {ticker}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"beta_cache_data2.csv\"\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Ticker\", \"CAGR\", \"Estimated_Beta\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"\\n📁 Done. Saved {len(data)} entries to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68675dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_cache_data=pd.read_csv(\"beta_cache_data.csv\")\n",
    "beta_cache_data2=pd.read_csv(\"beta_cache_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455eb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_beta_cache=pd.concat([beta_cache_data.csv,beta_cache_data2.csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d46c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ab30e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Nifty moved 0.19% in the last 24h.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_nifty_moving(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbc1c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_beta_cache.to_csv(\"merged_beta_cache.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb85e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'system_template' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm investing ₹1,00,000 in the IT sector over 5 years. My goal is aggressive growth — I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm okay with high risk and want an annual return of around 18\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m. Suggest the best stocks for this.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mportfolio_developer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m, in \u001b[0;36mportfolio_developer\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m      4\u001b[0m human_template \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Build the full ChatPromptTemplate\u001b[39;00m\n\u001b[0;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[1;32m----> 8\u001b[0m     SystemMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[43msystem_template\u001b[49m),\n\u001b[0;32m      9\u001b[0m     HumanMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(human_template),\n\u001b[0;32m     10\u001b[0m ])\n\u001b[0;32m     11\u001b[0m chain\u001b[38;5;241m=\u001b[39mprompt\u001b[38;5;241m|\u001b[39m model \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[0;32m     12\u001b[0m result_dict_string \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'system_template' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e8a118",
   "metadata": {},
   "source": [
    "PART 2- PORTFOLIO MANAGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8966b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "def get_google_news_rss(company, num_articles=5):\n",
    "    query = company.replace(\" \", \"+\")\n",
    "    feed_url = f\"https://news.google.com/rss/search?q={query}\"\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    \n",
    "    return [entry.title for entry in feed.entries[:num_articles]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a248b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_system_prompt = \"\"\"\n",
    "You are a financial sentiment analyst.\n",
    "\n",
    "Your job is to analyze news headlines about a company and return one word only along with the company name:\n",
    "- \"good\" if the overall sentiment is positive for the company\n",
    "- \"bad\" if the headlines indicate issues, scandals, losses, etc.\n",
    "- \"neutral\" if the news is mixed or non-impactful\n",
    "\n",
    "Only return one of: \"good\", \"bad\", or \"neutral\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cd9471a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HDFC Bank share price hits record high. Is HDB Financial IPO the reason? - Mint',\n",
       " 'HDFC Bank Dividend: Record date announced for shareholder eligibility; buy before deadline to get paid - Moneycontrol',\n",
       " 'Another HC judges recuses from hearing HDFC Bank CEO’s plea against bribery charge - The Indian Express',\n",
       " 'PhonePe, HDFC Bank launch co-branded RuPay credit card with UPI integration - CNBC TV18',\n",
       " 'Second FD rate cut in June: HDFC Bank revises interest rate on this tenure - The Economic Times']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_google_news_rss(\"HDFCBANK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080266af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===  Sentiment Analysis Summary ===\n",
      "\n",
      "LTIM: Ltim - good\n",
      "✅ All good\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "def sentiment_anal(portfolio):\n",
    "    df = pd.read_csv(portfolio)\n",
    "    tickers = df['ticker'].tolist() \n",
    "\n",
    "    sentiments = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        headlines = get_google_news_rss(ticker)  # fetch for this ticker only\n",
    "        if not headlines:\n",
    "            print(f\"⚠️ No headlines found for {ticker}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        headline_string = \"\\n\".join(headlines)\n",
    "    \n",
    "        prompt3 = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(sentiment_system_prompt),\n",
    "            HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "        ])\n",
    "\n",
    "        chain = prompt3 | model | StrOutputParser()\n",
    "        sentiment = chain.invoke({\"input\": f\"Analyze the sentiment of the following headlines:\\n\\n{headline_string}\"})\n",
    "    \n",
    "        sentiments[ticker] = sentiment.strip().lower()\n",
    "        time.sleep(random.uniform(3, 6))  # polite scraping\n",
    "\n",
    "    # Flag stocks for review\n",
    "    print(\"\\n===  Sentiment Analysis Summary ===\\n\")\n",
    "    for ticker in tickers:\n",
    "        sentiment = sentiments.get(ticker, \"unknown\")\n",
    "        print(f\"{ticker}: {sentiment.capitalize()}\")\n",
    "\n",
    "        if sentiment in [\"bad\", \"negative\", \"bearish\"]:\n",
    "            print(\"⚠️ Action: Review this company\\n\")\n",
    "        elif sentiment == \"unknown\":\n",
    "            print(\"❓ Action: Sentiment not available\\n\")\n",
    "        else:\n",
    "            print(\"✅ All good\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e572c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "348e034c",
   "metadata": {},
   "source": [
    "PART 3- ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed2e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores  import Chroma\n",
    "from langchain_community.llms import ollama\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928a4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def download_latest_research_report(company_ticker, save_dir=\"research_reports\"):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    url = f\"https://ticker.finology.in/company/{company_ticker.upper()}\"\n",
    "\n",
    "    try:\n",
    "        html = requests.get(url, headers=headers).text\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    try:\n",
    "        title_text = soup.title.text\n",
    "        company_name = title_text.split(\"|\")[0].strip()\n",
    "    except:\n",
    "        company_name = company_ticker.upper()\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    report_list = soup.select(\"ul.reportsli li\")\n",
    "    latest_date = None\n",
    "    latest_link = None\n",
    "    latest_source = None\n",
    "\n",
    "    for item in report_list:\n",
    "        badge = item.select_one(\".badge-research\")\n",
    "        if badge:\n",
    "            anchor = item.find(\"a\", href=True)\n",
    "            date_text = item.select_one(\"small.text-grey\")\n",
    "            if not anchor or not date_text:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                date = datetime.strptime(date_text.text.strip(), \"%d %b %Y\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if (latest_date is None) or (date > latest_date):\n",
    "                latest_date = date\n",
    "                latest_link = anchor['href']\n",
    "                latest_source = anchor.text.strip().replace(\"Report By:\", \"\").replace(\"Report by:\", \"\").strip()\n",
    "\n",
    "    if not latest_link:\n",
    "        return None\n",
    "\n",
    "    safe_name = re.sub(r'\\W+', '_', company_name)\n",
    "    source_tag = re.sub(r'\\W+', '_', latest_source)\n",
    "    filename = f\"{safe_name}_Research_{latest_date.strftime('%Y')}_{source_tag}.pdf\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(latest_link, timeout=15)\n",
    "        if \"application/pdf\" in response.headers.get(\"Content-Type\", \"\").lower():\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            return filename\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e33d6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=download_latest_annual_report(\"HDFCBANK\", save_dir=\"reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a9d96d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDFC_Bank_Ltd_Share_Price_Today_Market_Cap_Price_Chart_Balance_Sheet_Annual_Report_2024.pdf\n"
     ]
    }
   ],
   "source": [
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca222a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, save_txt=False, txt_output_dir=\"txt_outputs\"):\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"[!] File not found: {pdf_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "\n",
    "        text = text.strip()\n",
    "\n",
    "        if save_txt:\n",
    "            os.makedirs(txt_output_dir, exist_ok=True)\n",
    "            raw_name = os.path.basename(pdf_path).replace(\".pdf\", \"\")\n",
    "            safe_name = re.sub(r\"\\W+\", \"_\", raw_name)\n",
    "            txt_filename = f\"{safe_name}.txt\"\n",
    "            txt_path = os.path.join(txt_output_dir, txt_filename)\n",
    "            with open(txt_path, \"w\", encoding=\"utf-8\") as out:\n",
    "                out.write(text)\n",
    "            print(f\"✅ Saved extracted text to: {txt_path}\")\n",
    "            return txt_filename\n",
    "\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Failed to extract from {pdf_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04c90a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved extracted text to: txt_outputs\\HDFC_Bank_Ltd_Share_Price_Today_Market_Cap_Price_Chart_Balance_Sheet_Annual_Report_2024.txt\n"
     ]
    }
   ],
   "source": [
    "pdf_path = os.path.join(\"reports\", filename)\n",
    "txt_file = extract_text_from_pdf(pdf_path, save_txt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5d4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.schema.output_parser import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eecb5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df707f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "893b18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def RAG(query, force=False):\n",
    "    start = time.time()\n",
    "    print(\"⏱ RAG pipeline started...\")\n",
    "\n",
    "    # 1. Extract company name\n",
    "    system_prompt = \"\"\"\n",
    "    You are an assistant that extracts company names or stock tickers from user questions.\n",
    "    Return only the ticker/company name, don't explain anything.\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "        HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "    ])\n",
    "\n",
    "    llm = Ollama(model=\"llama3.2\")\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    company_name = chain.invoke({\"query\": query}).strip()\n",
    "    company_name = re.sub(r\"\\.(NS|BO|NSE|BSE)$\", \"\", company_name.strip(), flags=re.IGNORECASE)\n",
    "    company_ticker = re.sub(r'\\W+', '', company_name).upper()\n",
    "    print(f\"🔍 Extracted company: {company_name} → Ticker: {company_ticker} [{time.time() - start:.2f}s]\")\n",
    "\n",
    "    # 2. Vector DB path\n",
    "    db_dir = os.path.abspath(f\"vector_db/{company_ticker}\")\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "    if os.path.exists(db_dir) and len(os.listdir(db_dir)) > 0 and not force:\n",
    "        print(f\"📦 Using cached vector DB at {db_dir}\")\n",
    "        db = Chroma(persist_directory=db_dir, embedding_function=embeddings)\n",
    "\n",
    "    else:\n",
    "        print(f\"📄 Rebuilding vector DB for {company_name}...\")\n",
    "\n",
    "        # Download and extract\n",
    "        filename = download_latest_research_report(company_ticker, save_dir=\"reports\")\n",
    "        if not filename:\n",
    "            return f\"[!] Couldn't get report for '{company_name}'\"\n",
    "\n",
    "        pdf_path = os.path.join(\"reports\", filename)\n",
    "        txt_file = extract_text_from_pdf(pdf_path, save_txt=True)\n",
    "\n",
    "        if not txt_file:\n",
    "            return f\"[!] PDF extraction failed: {filename}\"\n",
    "\n",
    "        txt_file = os.path.basename(txt_file).strip()\n",
    "        if not txt_file.endswith(\".txt\"):\n",
    "            txt_file += \".txt\"\n",
    "\n",
    "        txt_path = os.path.abspath(os.path.join(\"txt_outputs\", txt_file))\n",
    "        if not os.path.isfile(txt_path):\n",
    "            return f\"[!] Text file missing at {txt_path}\"\n",
    "\n",
    "        # Chunking\n",
    "        docs = TextLoader(txt_path, encoding=\"utf-8\").load()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        chunks = splitter.split_documents(docs)\n",
    "\n",
    "        # Embedding and DB creation\n",
    "        db = Chroma.from_documents(chunks, embeddings, persist_directory=db_dir)\n",
    "        db.persist()\n",
    "        print(f\"✅ Vector DB saved at {db_dir}\")\n",
    "\n",
    "    # 3. Retrieval + DEBUG: show top 3 chunks\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "    top_docs = retriever.get_relevant_documents(query)\n",
    "    print(\"\\n🔎 Top Retrieved Chunks:\")\n",
    "    for i, doc in enumerate(top_docs):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\\n{doc.page_content[:800]}\\n\")\n",
    "\n",
    "    # 4. QA\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "    response = qa_chain.run(query)\n",
    "\n",
    "    print(f\"✅ Done in {time.time() - start:.2f}s\")\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acb65815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱ RAG pipeline started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagnik giri\\AppData\\Local\\Temp\\ipykernel_864\\4264605044.py:41: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=db_dir, embedding_function=embeddings)\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Extracted company: HDFCBANK → Ticker: HDFCBANK [4.70s]\n",
      "📦 Using cached vector DB at c:\\Users\\Sagnik giri\\Downloads\\projects\\LangChainproj\\vector_db\\HDFCBANK\n",
      "\n",
      "🔎 Top Retrieved Chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "RESULT REVIEW\n",
      "BUY\n",
      "TP: Rs 2,213 |  16%\n",
      "HDFC BANK | Banking | 21 April 2025\n",
      "Asset quality remains resilient; eyes set on growth\n",
      "Niraj Jalan | Vijiya Rao\n",
      "▪ CD ratio continued to moderate with slowdown in credit growth, while\n",
      "research@bobcaps.in\n",
      "deposit growth higher than system growth\n",
      "▪ Asset quality remains pristine supported by lower slippages; credit\n",
      "cost stays stable at 40–50bps\n",
      "▪ Maintain BUY. Raise SOTP-based TP to Rs 2,213 (from Rs 2,008), set at\n",
      "2.5x FY27E ABV\n",
      "CD ratio continues to improve: CD ratio moderated to 96.5% in Q4FY25 (98.2% in Key changes\n",
      "Q3FY25) vs a high of 110.5% in Q3FY24. The moderation was driven by slowdown Target Rating\n",
      "in credit growth to 5.4% YoY vs deposit growth of 14.1% YoY higher than system  \n",
      "growth (~11%) in Q4FY25. HDFCB plans to reduce its CD ratio t\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "▪ Serviced 6.8 Mn clients via 134 branches, with 96% of active clients using digital\n",
      "platforms.\n",
      "▪ Despite weaker trading volumes, sustained strong presence with stable client base.\n",
      "▪ EPS was Rs 141.3; Book Value per Share at Rs 1,885 as of Mar’25.\n",
      "EQUITY RESEARCH 7 21 April 2025\n",
      "HDFC BANK\n",
      "Valuation methodology\n",
      "We estimate deposits growth to be in the 16-17.9% range in FY26-FY28E. Advances\n",
      "growth is likely to be lower in the 10.5-14% range during FY26-FY28E. This would result\n",
      "in a lower CD ratio going forward.\n",
      "Management has strategically chosen to steer away from aggressive market competition,\n",
      "prioritising profitability and margin sustainability over headline growth. It continues to\n",
      "follow a risk-based pricing approach on the asset side, ensuring yield discipline rather\n",
      "than chasing volume\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "than chasing volume. On the liability side, the bank plans to optimise its funding profile\n",
      "by repaying high-cost legacy borrowings and increasingly tapping cost-effective\n",
      "instruments such as infrastructure and affordable housing bonds. These measures are\n",
      "expected to ease pressure on funding costs and support margins in the coming quarters.\n",
      "We believe HDFCB has managed to outperform its large private sector peers in the past\n",
      "by effectively navigating business cycles, delivering stronger profitability and margins\n",
      "coupled with better asset quality. Amidst the noises on unsecured loans, tighter liquidity\n",
      "conditions and expectations of further CRR cut thus boosting liquidity, the bank is well-\n",
      "positioned to benefit. Hence, we maintain BUY with revised SOTP-based TP of Rs 2,213\n",
      "(from Rs 2,008); \n",
      "\n",
      "✅ Done in 54.81s\n",
      "I don't know what the PAT (Profit After Tax) ratio is for HDFCBANK this year, as the text provided does not mention it. It only mentions EPS (Earnings Per Share), which was Rs 141.3 as of Mar'25.\n"
     ]
    }
   ],
   "source": [
    "query=\"What is the PAT ratio for HDFCBANK this year?\"\n",
    "print(RAG(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8740c48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagnik giri\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cff2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acfa3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def delete_vector_db(company_name):\n",
    "    db_path = os.path.abspath(f\"vector_db/{company_name.replace(' ', '_')}\")\n",
    "    if os.path.exists(db_path):\n",
    "        shutil.rmtree(db_path)\n",
    "        print(f\"🧹 Deleted vector DB at: {db_path}\")\n",
    "    else:\n",
    "        print(f\"[!] No vector DB found at: {db_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099a772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Deleted vector DB at: c:\\Users\\Sagnik giri\\Downloads\\projects\\LangChainproj\\vector_db\\HDFC_BANK\n"
     ]
    }
   ],
   "source": [
    "delete_vector_db(\"HDFC_BANK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
